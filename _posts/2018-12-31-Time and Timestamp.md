---
layout: page
title: Several Papers about Time and Timestamp
tags: [Network, Distributed]
excerpt_separator: <!--more-->
typora-root-url: ../
---

> ç¥2019å¥½è¿ğŸ€

## Globally Synchronized Time via Datacenter Networks

### 0x00 å¼•è¨€ 

 2018å¹´æœ€åä¸€å¤©ï¼Œæ—¶å…‰åŒ†åŒ†ï¼Œæ¥çœ‹å‡ ç¯‡å…³äºæ—¶é—´çš„Papersã€‚è¿™ç¯‡Paperæ˜¯åœ¨æ•°æ®ä¸­å¿ƒå†…æ—¶é—´åŒæ­¥çš„ä¸€ä¸ªè®¾è®¡ã€‚Paperä¸­è®¤ä¸ºç›®å‰ä½¿ç”¨NTP å’Œ PTPéƒ½å­˜åœ¨ä¸€äº›é—®é¢˜ã€‚è¿™ç¯‡Paperä¸­æå‡ºäº†ä¸€ç§å«åšDatacenter Time Protocol(DTP)çš„æ—¶é’ŸåŒæ­¥åè®®ã€‚åœ¨Paperä¸­çš„æµ‹è¯•ç¯å¢ƒçš„æµ‹è¯•æ•°æ®è¡¨æ˜ï¼Œåœ¨ç›´æ¥è¿æ¥çš„æƒ…å†µä¸‹å¯ä»¥å®ç°å°é›¨25.6nsçš„è¯¯å·®ï¼Œåœ¨6è·³çš„æ—¶å€™è¿™ä¸ªæ•°å­—æ˜¯153.6ns,

```
... is bounded by 4TD where D is the longest distance between any two servers in a network in terms of number of hops and T is the period of the fastest clock (â‰ˆ 6.4ns). Moreover, in software, a DTP daemon can access the DTP clock with usually better than 4T (â‰ˆ 25.6ns) precision. As a result, the end-to-end precision can be better than 4T D + 8T nanoseconds
```

### 0x01 èƒŒæ™¯å’Œå­˜åœ¨çš„é—®é¢˜

ç½‘ç»œä¸­çš„æ—¶é’ŸåŒæ­¥å­˜åœ¨ä¸‹é¢çš„ä¸€äº›çš„è¯¯å·®æºï¼š

* éœ‡è¡å™¨åæ–œï¼Œè¿™ä¸ªçš„é—®é¢˜ä¸€èˆ¬éƒ½æ²¡æœ‰ä»€ä¹ˆåŠæ³•ç›´æ¥å»å¤„ç†ï¼›

* è¯»å–è¿œç¨‹æ—¶é’Ÿå­˜åœ¨çš„é—®é¢˜ï¼Œè¯»å–çš„æ“ä½œçš„æ­¥éª¤ä¸€èˆ¬å¦‚ä¸‹ï¼š

  ```
  1. Preparing a time request (reply) message
  2. Transmitting a time request (reply) message
  3. Packet traversing time through a network
  4. Receiving a time request (reply) message
  5. Processing a time request (reply) message
  ```

  è·å–æ—¶é—´æˆ³çš„æ“ä½œçš„è¯¯å·®å½±å“åˆ°1å’Œ5ï¼Œè®¡æ—¶ä¸ä¼šæ˜¯å®Œå…¨ç²¾ç¡®çš„ï¼Œå°±ä¼šç»™è·å–æ—¶é—´æˆ³é€ æˆè¯¯å·®ï¼›ç½‘ç»œæ ˆçš„è½¯ä»¶é—®é¢˜å½±å“åˆ°2å’Œ4ï¼Œç½‘ç»œæ ˆä¸­å¤„ç†å’Œä¼ è¾“æ•°æ®åŒ…å¸¦æ¥çš„ä¸ç¡®å®šçš„å»¶è¿Ÿï¼›ç½‘ç»œçš„æŠ–åŠ¨å½±å“åˆ°3ï¼Œç½‘ç»œéš¾å…å‘é€ä¸€äº›å°é—®é¢˜ï¼Œä¸ä¼šæ˜¯ä¸€ç›´æ˜¯å¹³ç¨³è¿è¡Œã€‚

* åŒæ­¥é¢‘ç‡çš„é—®é¢˜ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œè¶Šé¢‘ç¹çš„åŒæ­¥ç²¾ç¡®åº¦è¶Šé«˜ï¼Œå€’æ˜¯overheadä¹Ÿè¶Šå¤§ã€‚é€‰æ‹©ä»€ä¹ˆæ ·çš„é¢‘ç‡æ˜¯ä¸€ä¸ªæƒè¡¡çš„é—®é¢˜ã€‚

Paperä¸­è¿˜å¯¹ç›®å‰çš„ä¸€äº›è§£å†³æ–¹æ¡ˆå…¥NTPã€PTPå’ŒGPSä¹Ÿåšäº†åˆ†æ[1]ã€‚

### 0x02 åŸºæœ¬æ€è·¯

  DTPä¸­çš„ä¸€äº›å‡è®¾ï¼š ç½‘ç»œè®¾å¤‡ä½¿ç”¨çš„oscillators(éœ‡è¡å™¨)å­˜åœ¨ä¸€å®šçš„è¯¯å·®ï¼Œä½†æ˜¯è¿™ä¸ªè¯¯å·®åœ¨ä¸€å®šçš„èŒƒå›´å†…[fâˆ’0.0001f, f+0.0001f]ï¼Œåœ¨10Gçš„ä»¥å¤ªç½‘ä¸­ï¼Œè¿™ä¸ªfæ˜¯156.25MHzï¼›ä¸ç”¨è€ƒè™‘æ—¶é’Ÿçš„æ‹œå åº­é—®é¢˜ï¼›ä½¿ç”¨ç½‘ç»œçº¿ç¼†çš„é•¿åº¦ä¸€èˆ¬ä¸é•¿ï¼Œä¸è¶…è¿‡1kmï¼Œä¸€èˆ¬åœ¨10mä»¥å†…ã€‚DTPåè®®ä¸­ï¼Œæ¯ä¸ªç½‘ç»œç«¯å£æœ‰ä¸€ä¸ªå±€éƒ¨çš„è®¡æ•°å™¨ï¼Œè¿è¡Œåœ¨ç‰©ç†å±‚ï¼Œæ¯ä¸€ä¸ªæ—¶é’Ÿæ»´ç­”ä¼šé€’å¢ã€‚DTPç›´æ¥åœ¨ç‰©ç†å±‚æ“ä½œå±€éƒ¨è®¡æ•°å™¨ï¼Œäº¤æ¢æœºéœ€è¦é€šè¿‡å®ƒé¢å¤–çš„ä¸€éƒ¨å»åŒæ­¥å®ƒæ‰€æœ‰çš„ç«¯å£çš„å±€éƒ¨è®¡æ•°å™¨ã€‚å¦å¤–è¿˜ç»´æŒäº†ä¸€ä¸ªå…¨å±€çš„è®¡æ•°å™¨ï¼Œä¹Ÿæ˜¯æ¯æ¬¡æ—¶é’Ÿæ»´ç­”çš„æ—¶å€™é€’å¢ï¼Œä½†æ˜¯æ€»æ˜¯å»å®ƒå’Œæ‰€æœ‰çš„å±€éƒ¨è®¡æ•°å™¨ä¸­çš„æœ€å¤§çš„å€¼ã€‚ä¸€ä¸ªåŒæ­¥ä¸¤ä¸ªå¯¹ç­‰å®ä½“çš„ç®—æ³•çš„åŸºæœ¬çš„ä¼ªä»£ç å¦‚ä¸‹ï¼š

```
Algorithm 1 DTP inside a network port:
STATE:
  gc : global counter, from Algorithm 2
  lc â† 0 : local counter, increments at every clock tick 
  d â† 0 : measured one-way delay to peer p
 
TRANSITION:
  T0: After the link is established with p 
    lc â† gc
    Send (Init, lc)
  T1: After receiving (Init, c) from p
    Send (Init-Ack, c)
  T2: After receiving (Init-Ack, c) from p
    d â† (lc âˆ’ c âˆ’ Î±)/2 
  T3: After a timeout
    Send (Beacon, gc)
  T4: After receiving (Beacon, c) from p
   lc â† max(lc, c + d)
```

ç®—æ³•åˆ†ä¸º2æ­¥ï¼š

* INIT phaseï¼Œè¿™ä¸ªæ­¥éª¤æ˜¯ä¸ºæµ‹é‡ä¸¤ä¸ªå¯¹ç­‰å®ä½“ä¹‹é—´çš„å»¶è¿Ÿã€‚ç‰©ç†ç›¸è¿çš„ä¸¤è€…é€šè¿‡å‘é€INITæ¶ˆæ¯å’Œ INIT-ACKæ¶ˆæ¯æ¥æµ‹é‡RTTã€‚è¿™é‡Œçš„RTTä¸»è¦æœ‰ç‰©ç†å±‚çš„æ¥å—å‘é€å¤„ç†ã€ä¼ æ’­å»¶è¿Ÿå’Œthe clock domain crossing (CDC)å»¶è¿Ÿã€‚è¿™é‡Œä¸ç¡®å®šçš„å»¶è¿Ÿå°±æ˜¯CDCå»¶è¿Ÿã€‚

* BEACON phaseï¼Œåœ¨è¿™ä¸ªæ­¥éª¤ä¸­ï¼Œä¸¤ä¸ªå¯¹ç­‰å®ä½“å‘¨æœŸæ€§äº¤æ¢å®ƒä»¬å±€éƒ¨è®¡æ•°å™¨ã€‚ç”±äºæ¯ä¸ªæ—¶é’Ÿèµ°çš„å¿«æ…¢ä¸ä¸€æ ·ï¼Œè¿™ä¸ªè¯¯å·®ä¼šè¶Šæ¥è¶Šå¤§ï¼Œè¿™é‡Œä¼šé€‰æ‹©ä¸€ä¸ªæœ¬åœ°çš„å’Œè¿œç«¯çš„è¾ƒå¤§å€¼ä½œä¸ºæ–°çš„æ—¶é—´ã€‚æ“ä½œå¦‚æœå¾ˆé¢‘ç¹çš„è¯è¿™ä¸ªè¯¯å·®å°±å¯ä»¥ä¿æŒåœ¨ä¸€ä¸ªè¾ƒå°çš„èŒƒå›´å†…ã€‚

  ```
  STATE:
    gc: global counter
    {lci}: local counters TRANSITION:
  T5: at every clock tick
     gc â†max(gc + 1, {lci})
  ```

![dtp-device](/assets/img/dtp-device.png).

#### DTPé™ä½è¯¯å·®çš„æ€è·¯

  åˆ°è¿™é‡Œçœ‹DTPåè®®æœ¬èº«ä¹Ÿæ²¡æœ‰ä»€ä¹ˆç‰¹åˆ«çš„ï¼Œé‡ç‚¹åœ¨ä¸è®²æ¯ä¸€æ­¥çš„æ“ä½œçš„è¯¯å·®é™åˆ¶åœ¨ä¸€ä¸ªå¾ˆå°çš„èŒƒå›´ä¹‹å†…ã€‚DTPä¸ºä»€ä¹ˆèƒ½å¤Ÿå®ç°ä½è¯¯å·®ï¼Œ

* INIT é˜¶æ®µçš„one-wayçš„å»¶è¿Ÿä¸è¶…è¿‡2ä¸ªæ»´ç­”ï¼›
* åœ¨BEACONé—´éš”å†…çš„è¯¯å·®ä¸è¶…è¿‡2ä¸ªæ»´ç­”ï¼Œç”±äºå‰é¢çš„å¯èƒ½å­˜åœ¨çš„æ—¶é’ŸæŠ€æœ¯çš„åå·®ï¼Œè¿™é‡Œä¹Ÿå°±å¾—ä½¿å¾—è¿™ä¸ªé—´éš”ä¸è¶…è¿‡5000ä¸ªæ»´ç­”ï¼›
* è¿™æ ·çš„è¯ç›´æ¥è¿æ¥çš„å°±ä¸ä¼šè¶…è¿‡4ä¸ªæ»´ç­”Tï¼ŒTä¸º6.4nsï¼Œè¿™æ ·ä¹Ÿå°±æ˜¯25.6nsæ¥æ¥æºï¼›
* å¯¹äºå¤šæ¡çš„æƒ…å†µï¼Œæ¯ä¸€æ¡æœ€å¤šå¢åŠ 4ä¸ªæ»´ç­”çš„è¯¯å·®ï¼Œä¹Ÿå°±æ˜¯å‰é¢çš„6æ¡æƒ…å†µä¸‹è¯¯å·®å€¼çš„æ¥æºã€‚

å¦å¤–ï¼ŒDTPçš„ä½¿ç”¨æ˜¯éœ€è¦å¯¹ç¡¬ä»¶è¿›è¡Œä¸€äº›ä¿®æ”¹çš„ï¼Œ

```
A DTP-enabled device can be implemented with additional logic on top of the DTP-enabled ports. The logic maintains the 106-bit global counter as shown in Algorithm 2, which computes the maximum of the local counters of all ports in the device. The computation can be optimized with a tree-structured circuit to reduce latency, and can be performed in a deterministic number of cycles. 
```

<img src="/assets/img/dtp-low-level.png" alt="dtp-low-level" style="zoom:67%;" />

### 0x03 è¯„ä¼°

 è¿™é‡Œçš„å…·ä½“ä¿¡æ¯å¯ä»¥å‚çœ‹[1].

## Exploiting a Natural Network Effect for Scalable, Fine-grained Clock Synchronization

### 0x10 å¼•è¨€

  è¿™ç¯‡Paperæå‡ºäº†åŒæ ·ç”¨äºæ—¶é’ŸåŒæ­¥çš„HUYGENSç®—æ³•ï¼Œè¿™ä¸ªç®—æ³•çš„ç›®çš„å°±æ˜¯ä¸éœ€è¦å‘DTPå¯¹ç¡¬ä»¶è¿›è¡Œä¿®æ”¹ä¹Ÿèƒ½å®Œæˆè¿›åº¦åœ¨å‡ åä¸ªçº³ç§’çº§åˆ«çš„æ—¶é’ŸåŒæ­¥æ“ä½œã€‚å®ƒçš„æ€è·¯å­˜åœ¨ä¸åŒï¼Œå…·ä½“çš„ç®—æ³•ä¹Ÿå¤æ‚ä¹Ÿå¾ˆå¤šã€‚è¿™é‡Œå°±äº†è§£ä¸€ä¸‹åŸºæœ¬çš„æ€è·¯ï¼Œ

```
A NetFPGA-based verification in a 128-server, 2-stage Clos data center network shows that HUYGENS and HUYGENS-R achieve less than 12â€“15ns average error and under 30â€“45ns 99th percentile error at 40% network load. At 90% load, the numbers increase to 16â€“23ns and 45â€“58ns, respectively.
```

### 0x11 åŸºæœ¬æ€è·¯

 HUYGENSç®—æ³•çš„3ç‚¹çš„æ ¸å¿ƒæ€è·¯ï¼Œè¿™é‡Œçš„ç¬¬ä¸€äºŒæ¡çš„ç›®çš„å°±æ˜¯ä¸ºäº†æ›´åŠ ç²¾ç¡®åœ°å¤„ç†æµ‹é‡one-way propagation timesï¼Œä¸‹é¢ç¬¬3ç‚¹æ˜¯ä½¿ç”¨è®¾å¤‡è‡ªèº«æ¥é™ä½è¯¯å·®ï¼Œ

```
First, coded probes identify and reject impure probe dataâ€”data captured by probes which suffer queuing delays, random jitter, and NIC timestamp noise. 

Next, HUYGENS processes the purified data with Support Vector Machines, a widely-used and powerful classifier, to accurately estimate one-way propagation times and achieve clock synchronization to within 100 nanoseconds. 

Finally, HUYGENS exploits a natural network effectâ€”the idea that a group of pair-wise synchronized clocks must be transitively synchronizedâ€” to detect and correct synchronization errors even further.
```

åŸºæœ¬æ€è·¯çš„å‡ ç‚¹

* æ•°æ®ä¸­å¿ƒçš„ä¸€äº›ç‰¹ç‚¹ï¼Œç°åœ¨çš„å¾ˆå¤šæ•°æ®ä¸­å¿ƒç½‘ç»œä½¿ç”¨çš„æ˜¯FatTreeæˆ–è€…æ˜¯ç±»ä¼¼çš„æ–¹å¼ï¼Œå¯¹äºä¸¤ç«¯ABä¹‹é—´çš„é€šä¿¡çº¿è·¯å…·æœ‰å¯¹ç§°æ€§ã€‚å¦å¤–åœ¨ç½‘ç»œä¸¤ç‚¹ä¹‹é—´å­˜åœ¨è¯¸å¤šçš„å¯è¡Œçš„è·¯çº¿ï¼ŒåŠæ—¶åœ¨ç½‘ç»œåˆ©ç”¨ç‡æ¯”è¾ƒé«˜çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½æ‰¾åˆ°æ²¡ä»€ä¹ˆæ’é˜Ÿçš„è·¯çº¿ï¼›
* Coded probesï¼Œè¿™ä¸ªCoded probesæ“ä½œæ˜¯HUYGENSç®—æ³•çš„ç¬¬ä¸€æ­¥ï¼Œå®ƒçš„åšæ³•å°±æ˜¯é—´éš”sçš„æ—¶é—´ç»™åŒä¸€ä¸ªç›®çš„ç«¯å‘é€ä¸¤ä¸ªæ•°æ®åŒ…ï¼Œæ¥å—ç«¯æµ‹é‡æ¥å—åˆ°ä¸¤è€…çš„æ—¶é—´å·®ï¼Œå’Œå‘é€çš„é—´éš”å·®sæ¯”è¾ƒã€‚è¿™é‡Œåªä¼šé€‰æ‹©å‘é€é—´éš”ä¸ªæ¥å—é—´éš”çš„è¯¯å·®åœ¨è§„å®šçš„èŒƒå›´å†…çš„æ•°æ®ï¼Œè€Œè®²è¯¯å·®å¤ªå¤§çš„æ•°æ®ä¸¢å¼ƒã€‚è¿™ä¸ªæ–¹æ³•æ˜¯ç”¨æ¥æ›´åŠ ç²¾ç¡®åœ°æµ‹é‡OWDï¼›

<img src="/assets/img/dtp-coded-probes.png" alt="dtp-coded-probes" style="zoom: 80%;" />

* Support Vector Machinesï¼Œé€šè¿‡ä½¿ç”¨æ”¯æŒå‘é‡æœºï¼Œç¬¬ä¸€æ­¥è·å–çš„æ•°æ®ç»è¿‡SVMçš„å¤„ç†ç”¨æ¥æ›´åŠ ç²¾ç¡®åœ°ä¼°è®¡ä¸¤è¿™ä¸ªä¹‹é—´çš„OWDã€‚

![dtp-svm](/assets/img/dtp-svm.png)

* Network effectã€‚è¿™æ ·ä¸€ä¸ªä¾‹å­ï¼šåœ¨ä¸€æ¬¡åŒæ­¥æ“ä½œä¸­ï¼ŒBè®¤ä¸ºæ¯”Aè¶…å‰äº†20ä¸ªå•ä½çš„æ—¶é—´ï¼Œä½†æ˜¯å®é™…ä¸Šåªæ˜¯10ä¸ªã€‚äºŒABæ˜¯éƒ½å‘ç°ä¸äº†è¿™ä¸ªå…·ä½“çš„è¯¯å·®çš„å€¼çš„ã€‚å‡è®¾åœ¨ç½‘ç»œä¸­æœ‰ABCè¿™æ ·ä¸€ä¸ªç¯ï¼Œå®ƒä»¬åŒæ­¥çš„æ—¶å€™å‘ç°çš„è¯¯å·®å¦‚å›¾Bæœ€ä¸Šé¢çš„ã€‚ä¸€ä¸ªç¯çº¿ç›¸åŠ çš„å€¼ä¸º10ä¸ªå•ä½ä¹‹é—´ï¼Œå¾ˆæ˜¾ç„¶è¿™æ ·å°±å¯ä»¥å‘ç°å­˜åœ¨ç€è¯¯å·®ã€‚ä½†æ˜¯å…·ä½“çš„æƒ…å†µä¹Ÿæ˜¯ä¸ç¡®å®šçš„ï¼Œå¯èƒ½çš„æƒ…å†µå¦‚ä¸‹é¢çš„ä¸¤ä¸ªå°å›¾æ‰€ç¤ºã€‚åœ¨Paperä¸­çš„ç®—æ³•ä¸­ï¼Œä¼šé€‰æ‹©å³è¾¹çš„å¤„ç†æ–¹å¼ï¼Œå› ä¸ºå°†â€œloop offset surplusâ€œå¹³å‡å¤„ç†äº†ã€‚æ³¨æ„è¿™ä¸ªåªæ˜¯å¤„ç†å¼‚å¸¸çš„ä¸€ç§æ–¹å¼ï¼Œå¹¶ä¸ä¸€å®šå°±ä½œå‡ºäº†æœ€ä½³çš„åšæ³•ã€‚å¦å¤–ï¼Œåœ¨æ›´å¤šçš„â€œç¯â€çš„æ—¶å€™ï¼Œä¹Ÿæ ¹æ®minimum-normçš„å¤„ç†æ–¹å¼ï¼Œæ³¨æ„(c)çš„å¤„ç†è¡¨ç¤ºã€‚

![dtp-netword-effect](/assets/img/dtp-netword-effect.png)

### 0x12 å…·ä½“ç®—æ³•

 è¿™é‡Œç®—æ³•çš„ç»†èŠ‚æ¯”è¾ƒå¤šemmmmmï¼Œ.....TODO[1]

### 0x13 è¯„ä¼°

  è¿™é‡Œçš„å…·ä½“ä¿¡æ¯å¯ä»¥å‚çœ‹[1].

## A Scalable Ordering Primitive for Multicore Machines

### 0x20 å¼•è¨€

  è¿™ç¯‡Paperå¤„ç†çš„é—®é¢˜æ˜¯å¤šæ ¸ç‰¹åˆ«æ˜¯å¤šå¤„ç†å™¨æœºå™¨ä¸Šé¢çš„ç¡¬ä»¶æ—¶é’ŸåŒæ­¥çš„é—®é¢˜ã€‚ä¸å°‘çš„åŒæ­¥æ–¹æ³•ä¾‹å¦‚RLUä»¥åŠä¸€äº›æ•°æ®åº“ï¼Œç‰¹åˆ«æ˜¯ä½¿ç”¨MVCCæœºåˆ¶çš„ä¸€äº›æ•°æ®åº“ç‰¹åˆ«ä¾èµ–äºæ—¶é—´æˆ³çš„åˆ†é…ã€‚åœ¨ä¸€äº›æƒ…å†µä¸‹ï¼Œè¿™ä¸ªæ—¶é—´æˆ³çš„åˆ†é…ä¹Ÿä¼šæˆä¸ºå½±å“æ€§èƒ½çš„ä¸€ä¸ªå› ç´ ã€‚æƒ³TicToc[4]ä½¿ç”¨äº†è‡ªå·±çš„ä¸€äº›æ–¹æ³•ã€‚è¿™ç¯‡Paperæå‡ºäº†ä¸€ä¸ªåä¸ºOrdoçš„è§£å†³æ–¹å¼ï¼ŒåŸºæœ¬çš„æ€è·¯å’ŒSpannerçš„TrueTimeçš„ä¸€è‡´çš„ã€‚

```
Our evaluation shows that there is a possibility that the clocks are not synchronized on two architectures (Intel and ARM) and that Ordo generally improves the efficiency of several algorithms by 1.2â€“39.7Ã— on various architectures.
```

### 0x21 åŸºæœ¬æ€è·¯

Ordoçš„åŸºæœ¬æ€è·¯å’ŒTrueTimeæ˜¯ä¸€æ ·çš„ï¼Œä¹Ÿå°±æ˜¯è¯´åœ¨Ordoé‡Œé¢ä¸¤ä¸ªæ—¶é—´æˆ³çš„å¤§å°çš„æ¯”è¾ƒå¿…é¡»è®©ä¸€ä¸ªè¶…è¿‡orå°äºå¦å¤–ä¸€ä¸ªå€¼ä¸€ä¸ªBOUNDARYçš„å€¼ï¼Œæ‰èƒ½æ˜ç¡®å®ƒä»¬ä¹‹é—´çš„å‰åå…³å¿ƒã€‚è€Œå·®å€¼åœ¨è¿™ä¸ªBOUNDARYå€¼ä¹‹é—´çš„æ—¶å€™ï¼Œåªèƒ½åšä¸ç¡®å®šçš„åˆ¤æ–­ã€‚

```python
def get_time(): # Get timestamp without memory reordering 
    return hardware_timestamp() # Timestamp instruction

def cmp_time(time_t t1, time_t t2): # Compare two timestamps 
    if t1 > t2 + ORDO_BOUNDARY: # t1 > t2
        return 1
    elif t1 + ORDO_BOUNDARY < t2: # t1 < t2
        return -1
    return 0

def new_time(time_t t): # New timestamp after ORDO_BOUNDARY
    while cmp_time(new_t = get_time(), t) is not 1:
        continue # pause for a while and retry
    return new_t # new_t is greater than (t + ORDO_BOUNDARY)
```

 è¿™æ ·Ordoè¦å¤„ç†çš„ä¸€ä¸ªä¸»è¦é—®é¢˜åŠæ—¶è¿™ä¸ªORDO_BOUNDARYçš„æµ‹é‡ï¼ŒOrdoå¿…é¡»ä¿è¯è¿™ä¸ªä¸å°äºå®é™…æ—¶é’Ÿä¹‹é—´çš„åå·®ã€‚è¿™å¯ä»¥ç®€åŒ–ä¸ºä¸¤ä¸ªæ ¸å¿ƒç›´æ¥è·å–çš„æ—¶é—´æˆ³å·®å€¼æœ€å¤§çš„è®¡ç®—ï¼Œ

```python
runs = 100000 # multiple runs to minimize overheads 
shared_cacheline = {"clock": 0, "phase": INIT}

def remote_worker(): 
    # å°è¯•å¤šæ¬¡
    for i in range(runs):
        while shared_cacheline["phase"] != READY: 
            read_fence() # flush load buffer     
        ATOMIC_WRITE(shared_cacheline["clock"], get_time()) 
        barrier_wait() # synchronize with the local_worker
    
def local_worker():
    min_offset = INFINITY 
    # å°è¯•å¤šæ¬¡
    for i in range(runs):
        # æ¯æ¬¡æµ‹é‡éƒ½ä¼šåˆå§‹åŒ–ï¼Œé¿å…ä¸åŒæ¬¡æµ‹é‡çš„ç›¸äº’å½±å“
        shared_cacheline["clock"] = 0 
        shared_cacheline["phase"] = READY 
        while shared_cacheline["clock"] == 0:
            read_fence() # flush load buffer
        # æµ‹é‡å¤šæ¬¡å–æœ€å°çš„å€¼
        min_offset = min(min_offset, get_time() - shared_cacheline["clock"])
        barrier_wait() # synchronize and restart the process
     return min_offset

def clock_offset(c0, c1):
    # ä¸‹é¢ä¸¤ä¸ªä¼šåŒæ—¶è¿è¡Œ
    run_on_core(remote_worker, c1) 
    return run_on_core(local_worker, c0)

def get_ordo_boundary(num_cpus):
    global_offset = 0
    # æµ‹é‡ä¸åŒæ ¸å¿ƒä¹‹é—´çš„ç»„æˆï¼Œå–æœ€å¤§å€¼
    for c0, c1 in combinations([0 ... num_cpus], 2):
        global_offset = max(global_offset, max(clock_offset(c0, c1), clock_offset(c1, c0)))
    return global_offset
```

åˆ©ç”¨Ordoçš„APIæ”¹é€ RLUçš„ä¸€ä¸ªä¾‹å­ï¼Œå¤šåŸæœ‰é€»è¾‘çš„æ”¹åŠ¨æ˜¯å¾ˆå°çš„ï¼Œ

<img src="/assets/img/ordo-rlu.png" alt="ordo-rlu" style="zoom:80%;" />

### 0x22 è¯„ä¼°

  è¿™é‡Œå…·ä½“çš„ä¿¡æ¯å¯ä»¥å‚çœ‹[3]ã€‚

## å‚è€ƒ

1. Globally Synchronized Time via Datacenter Networks, SIGCOMM'16.
2. Exploiting a Natural Network Effect for Scalable, Fine-grained Clock Synchronization, NSDI'18.
3. A Scalable Ordering Primitive for Multicore Machines, Eurosys â€™18.
4. TicToc: Time Traveling Optimistic Concurrency Control, SIGMOD 2016.